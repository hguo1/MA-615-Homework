---
title: "615 final"
author: "He Guo"
date: "11/30/2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(knitr)
library(scales)
library(janeaustenr)
library(dplyr)
library(stringr)
library(ggplot2)
library(tidyr)
library(wordcloud)
library(reshape2)

```


## Review Analysis

$~~~$ This study use review file in Yelp dataset.  There is a stars variable record the stars of each business.  This study wants to mark the stars of thoes business as High, Mid, and Low.  When stars greater to 4, rate is High.  When stars is greater and equals to 3, and lower and equals to 4, rate is Mid.  When stars is lower than 3, rate is Low.


$~~~$The study apply text analysis by using text variable and rate variable.  Text is review from users of each business.  At first, the study separate the text variable in to words.  In the other words, the study splits sentences into words, and group by the Rate variable.  Since this study wants to analysis review between different Rate.  
```{r, echo = FALSE}
review <- read.csv("review.csv")
review$Rate[review$stars>4]<-"High"
review$Rate[review$stars>=3 & review$stars<=4 ]<-"Mid"
review$Rate[review$stars<3]<-"Low"
re.mining<-data.frame(review$Rate,review$text)
re.mining$review.text<-as.character(re.mining$review.text)
T.mining <-re.mining %>%group_by(review.Rate)%>%mutate(linenumber = row_number())%>%unnest_tokens(word, review.text) 

```

## Sentiment

$~~~$ The current study want to analysis the positive/negative sentiment about the review from userd. The the study use lexicon from tidytext package, and we use bing lexicon categorizes words to apply this analysis.  The bing lexicon categorizes words has positive and negative categories.

$~~~$The study want to estimates how sentiment changes within different Rate categories.  After that the study find the sentiment score for each word usinf Bing lexicon and inner_join() methods.  Because the review section is too large, it is not good for doing text analysis.  Then, the study decide using 80% lines to apply this analysis.  
```{r, echo = FALSE}
T.mining_sentiment <- T.mining %>%
  inner_join(get_sentiments("bing"), by = "word") %>%
  count(review.Rate, index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
```


$~~~$ According to the following plot, users post positive review to business in High and mid Rate.  Users post a higher positive sentiment score to business in High Rate.  There are some negative score to business in low Rate.  It means that people will post neigative review to  business in low Rate.  
```{r, echo = FALSE}


ggplot(T.mining_sentiment, aes(index, sentiment, fill = review.Rate)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~review.Rate, ncol = 2, scales = "free_x")
```

$~~~$Then the study wants to know what is the most common positive score and neigative score for the review from users.  The current study uses count() with  arguments of both word and sentiment, we find out how much each word contributed to positive and negative sentiment. 

```{r, echo = FALSE}
bing_word_counts <- T.mining %>%
  inner_join(get_sentiments("bing"),by = "word") %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()


```

$~~~$The following plot shows that the words contirbutes the most to negative is bad.   The words contirbutes the most to positive is good.

```{r, echo = FALSE}
bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()
```

## Words Clouds
$~~~$ The following plot is words clouds. It shows the most frequency words are food, service.

```{r, echo = FALSE}


T.mining %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

$~~~$The study use group_by and join to get the most frequence words in Reviews text from users in Yelp.

```{r, echo = FALSE}
Rate_words <- re.mining %>%
  unnest_tokens(word, review.text) %>%
  count(review.Rate, word, sort = TRUE)

total_words <- Rate_words %>% 
  group_by(review.Rate) %>% 
  summarize(total = sum(n))

book_words <- left_join(Rate_words, total_words)
```

$~~~$n is  is the number of times that word is used in Reviews text and total is the total words in Reviews text. In the followling figure, it shows that  the distribution of n/total for each Rate category.  

```{r, echo = FALSE}
book_words<-na.omit(book_words)

ggplot(book_words, aes(n/total, fill = review.Rate)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~review.Rate, ncol = 2, scales = "free_y")

```


## Zipf's Law

$~~~$The study use Zipf's Law for Reviews text.  The rank variable gives the rank of each word in the frequency table, and the table is order by n.  Zipf's Law is visualized by the plot of freq_by_rank. Rank is on x-axis and term frequency is on y-axis.  The plot is on log scales.

```{r, echo = FALSE}
freq_by_rank <- book_words %>% 
  group_by(review.Rate) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total)


```

```{r, echo = FALSE}
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = review.Rate)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```


$~~~~$According to the plot, we can see that three categories are simlilar to each other, and the relationship between rank and frequency have a negative slop.  The study fit a linear regression with $log(term frequency)$ and $log(rank)$.


```{r, echo = FALSE}
rank_subset <- freq_by_rank %>% 
  filter(rank < 500,
         rank > 10)

lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
```


$~~~~$After get the linear regression, we add the fitted line into ggplot.

```{r, echo = FALSE}
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = review.Rate)) + 
  geom_abline(intercept = -0.8477 , slope = -1.0096, color = "gray50", linetype = 2) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```


## Consecutive Words

$~~~~$Next, the stuy wants to analysis the most common phrase for three Rate category.  The study use unnest_tokens() to estimate the pairs of two consecutive words.  The study separate the phrase in word1, and word2.  After delete the words does not have meaning, the study use unite() to recombine word1 and word2.   
```{r, echo = FALSE}


mining_bigrams <- re.mining %>%
  unnest_tokens(bigram,review.text , token = "ngrams", n = 2)

bigrams_separated <- mining_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)


bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)
bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

```


$~~~~$ The study compute the tf_idf for bigrams across Rate category. tf_idf return how important a phrase in review text of users in Yelp.  The following plot visualized the tf_idf within each Rate category.
```{r, echo = FALSE}

mining_tf_idf <- bigrams_united %>%
  count(review.Rate, bigram) %>%
  bind_tf_idf(bigram, review.Rate, n) %>%
  arrange(desc(tf_idf))

knitr::kable(head(mining_tf_idf))%>%kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

```{r, echo = FALSE}
mining_tf_idf %>%
  group_by(review.Rate) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(bigram = reorder(bigram, tf_idf)) %>%
  ggplot(aes(bigram, tf_idf, fill = review.Rate)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~review.Rate, scales = "free_y") +
  labs(y = "tf_idf",
       x = NULL) +
  coord_flip()
```

